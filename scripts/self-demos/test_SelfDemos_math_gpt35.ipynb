{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"../../data/math/test_demos.json\"\n",
    "result_path = \"../../result/self_demos\"\n",
    "keys_file_path = \"../../utils/raw_keys.txt\"\n",
    "\n",
    "\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "suffix = \"math_gpt35\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    raw_data = json.load(f)\n",
    "    \n",
    "# raw_data = raw_data[:5]\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_list = [0] * len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "for raw_item in tqdm(raw_data):\n",
    "    item = {}\n",
    "    item['Question'] = raw_item['problem']\n",
    "    item['Answer'] = raw_item['answer']\n",
    "    \n",
    "    item['Demos_Q'] = ''\n",
    "    item['Demos_QA'] = ''\n",
    "    \n",
    "    for demo in raw_item['demos']:\n",
    "        item['Demos_Q'] += f\"Question: {demo['problem']}\\n\\n\"\n",
    "        item['Demos_QA'] += f\"Question: {demo['problem']}\\nAnswer: {demo['solution']}\\n\\n\"\n",
    "        \n",
    "    data.append(item)\n",
    "    \n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openai import OpenAIKey, create_response_chat\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "openai_key = OpenAIKey(keys_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Query Understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_template = \"\"\"In this task, you need to give a general understanding of mathematical problems, which can be applied to all similar questions in the same scenario.\n",
    "There are 7 categories of topics: Intermediate Algebra, Precalculus, Number Theory, Geometry, Prealgebra, Algebra, Counting & Probability.\n",
    "\n",
    "# Problem:\n",
    "{Question}\n",
    "\n",
    "# Instruction: Generate a general understanding.\n",
    "Give a general understanding of this problem in one line. Highlight the general solution methodologies to solve this type of problems. Focus on the problem-solving approach without delving into specific numerical values or answers.\n",
    "You can refer to this template for your understanding: This problem involves...To solve this type of problem...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for item in data:\n",
    "    \n",
    "    prompt = step1_template.format(\n",
    "        Question=item['Question']\n",
    "    )\n",
    "    \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(prompt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "raw_step1_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    try_times = 0\n",
    "    while try_times < 5:\n",
    "        try: \n",
    "            result = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                ],\n",
    "                max_tokens=512,\n",
    "                temperature=0\n",
    "            )\n",
    "            # print(result)\n",
    "            raw_step1_result_list.append(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            try_times += 1\n",
    "            if try_times == 5:\n",
    "                raw_step1_result_list.append('None')\n",
    "                skip_list[i] = 1\n",
    "            openai_key.process_error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step1.json\"), \"w\") as f:\n",
    "    json.dump(raw_step1_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step1.json\"), 'r', encoding='utf8') as input_file:\n",
    "    raw_step1_result_list = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_result_list = []\n",
    "\n",
    "def extract_main_info(text):\n",
    "    lines = text.split('\\n')\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "    text = ' '.join(lines)\n",
    "    return text\n",
    "\n",
    "for i in range(len(raw_step1_result_list)):\n",
    "\n",
    "    clean_str = extract_main_info(raw_step1_result_list[i])\n",
    "    \n",
    "    if clean_str != '':\n",
    "        step1_result_list.append(clean_str)\n",
    "    else:\n",
    "        step1_result_list.append('None')\n",
    "        skip_list[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Query-aware Demo Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_template = \"\"\"In this task, you need to recall mathematical problems. When presented with a math problem, recall relevant problems as examples. These examples are helpful in answering the initial problem.\n",
    "\n",
    "# Problem:\n",
    "## The initial problem:\n",
    "{Question}\n",
    "\n",
    "## The Understanding you can refer to:\n",
    "{Understanding}\n",
    "\n",
    "# Demonstration of format:\n",
    "{Demos_QA}# Instruction: Recall relevant problem.\n",
    "Recall one example of math problem that is relevant to the initial problem. Your problems should be distinct from the initial problem (e.g., involving different numbers and names). \n",
    "- After \"Question: \", describe the problem you generate in one line.\n",
    "- After \"Answer: \", Explain the step-by-step solution and enclose the ultimate answer in \\\\boxed{{}}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for generated_understanding, item in zip(step1_result_list, data):\n",
    "    \n",
    "    prompt = step2_template.format(\n",
    "        Demos_QA=item[\"Demos_QA\"],\n",
    "        Question=item['Question'],\n",
    "        Understanding=generated_understanding\n",
    "    )\n",
    "    \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_step2_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(prompt_list))):\n",
    "    if skip_list[i] == 1:\n",
    "        raw_step2_result_list.append('None')\n",
    "        continue\n",
    "    \n",
    "    demo_candidate = []\n",
    "    \n",
    "    for _ in range(5):\n",
    "        try_times = 0\n",
    "        while try_times < 10:\n",
    "            try: \n",
    "                result = create_response_chat(\n",
    "                    MODEL,\n",
    "                    prompt_input=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                    ],\n",
    "                    max_tokens=512,\n",
    "                    temperature=0.8\n",
    "                )\n",
    "                # print(result)\n",
    "                demo_candidate.append(result)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                try_times += 1\n",
    "                openai_key.process_error(e)\n",
    "    \n",
    "    raw_step2_result_list.append(demo_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step2.json\"), \"w\") as f:\n",
    "    json.dump(raw_step2_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step2.json\"), 'r', encoding='utf8') as input_file:\n",
    "    raw_step2_result_list = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_result_list = []\n",
    "\n",
    "def extract_main_info(text):\n",
    "    \n",
    "    text = text.replace('Question:\\n', 'Question: ').replace('Question: \\n', 'Question: ')\n",
    "    text = text.replace('Answer:\\n', 'Answer: ').replace('Answer: \\n', 'Answer: ')\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    lines = [line.strip() for line in lines if line.strip() != '']\n",
    "    \n",
    "    Q_lines = [line for line in lines if re.match(r'^(question)', line, re.IGNORECASE)]\n",
    "    A_lines = [line for line in lines if re.match(r'^(answer)', line, re.IGNORECASE)]\n",
    "    \n",
    "    Q_lines = [line for line in Q_lines if len(line) > 20]\n",
    "    A_lines = [line for line in A_lines if len(line) > 20]\n",
    "    \n",
    "    if len(Q_lines) != 1 or len(A_lines) != 1:\n",
    "        return ''\n",
    "    \n",
    "    index1 = lines.index(Q_lines[0])\n",
    "    index2 = lines.index(A_lines[0])\n",
    "    if index1 > index2:\n",
    "        return ''\n",
    "    \n",
    "    Answer_lines = \" \".join(lines[index2:])\n",
    "    \n",
    "    result = Q_lines[0] + '\\n' + Answer_lines + '\\n'\n",
    "    \n",
    "    return result\n",
    "\n",
    "for i in range(len(raw_step2_result_list)):\n",
    "    \n",
    "    demo_candidate = []\n",
    "    for demo in raw_step2_result_list[i]:\n",
    "        \n",
    "        clean_result = extract_main_info(demo)\n",
    "        \n",
    "        if clean_result != '':\n",
    "            demo_candidate.append(clean_result)\n",
    "    \n",
    "    demo_candidate = list(set(demo_candidate))\n",
    "    \n",
    "    if len(demo_candidate) > 2:\n",
    "        step2_result_list.append(demo_candidate)\n",
    "    else:\n",
    "        step2_result_list.append(['None'])\n",
    "        skip_list[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step2_skip.json\"), \"w\") as f:\n",
    "    json.dump(skip_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Post-checking and Refining of Demos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_template = \"\"\"In this task, you need to check the correctness of these math Q&A pairs and select the two best examples to keep, for answering the final problem.\n",
    "\n",
    "# The final Problem:\n",
    "{Question}\n",
    "\n",
    "# Check List:\n",
    "- The calculation process in solution must be correct and without ambiguity.\n",
    "- The examples should be relevant and helpful in solving the final problem.\n",
    "\n",
    "# Examples to be checked:\n",
    "{generated_demonstration}# Instruction:\n",
    "Select two best examples to keep. If there are not enough correct and helpful examples, just keep one.\n",
    "For your answer:\n",
    "- After \"Selection: \", give the serial numbers of your choice in the format of <x>, <y>.\n",
    "- After \"Explanation: \", give the reason why you keep this example.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for generated_demonstration, item in zip(step2_result_list, data):\n",
    "    \n",
    "    demo_string = ''\n",
    "    for i, demo in enumerate(generated_demonstration):\n",
    "        demo_string += f\"Example <{i+1}>:\\n{demo}\\n\"\n",
    "    \n",
    "    prompt = step3_template.format(\n",
    "        Question=item['Question'],\n",
    "        generated_demonstration=demo_string\n",
    "    )\n",
    "    \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_step3_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(prompt_list))):\n",
    "    if skip_list[i] == 1:\n",
    "        raw_step3_result_list.append('None')\n",
    "        continue\n",
    "    try_times = 0\n",
    "    while try_times < 5:\n",
    "        try: \n",
    "            result = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                ],\n",
    "                max_tokens=64,\n",
    "                temperature=0\n",
    "            )\n",
    "            # print(result)\n",
    "            raw_step3_result_list.append(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            try_times += 1\n",
    "            if try_times == 5:\n",
    "                raw_step3_result_list.append('None')\n",
    "                skip_list[i] = 1\n",
    "            openai_key.process_error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(result_path, f\"{suffix}_step3.json\"), \"w\") as f:\n",
    "    json.dump(raw_step3_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(result_path, f\"{suffix}_step3.json\"), 'r', encoding='utf8') as input_file:\n",
    "    raw_step3_result_list = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_result_list = []\n",
    "\n",
    "for i in range(len(raw_step3_result_list)):\n",
    "    if skip_list[i] == 1:\n",
    "        step3_result_list.append('None')\n",
    "    else: \n",
    "        matches = re.findall(r'<[1-5]>', raw_step3_result_list[i])\n",
    "        matches = list(set(matches))\n",
    "        \n",
    "        if not matches or len(matches) > 2:\n",
    "            step3_result_list.append('None')\n",
    "            skip_list[i] = 1\n",
    "            continue\n",
    "        \n",
    "        extracted_numbers = [int(match[1]) for match in matches]\n",
    "        result = ''\n",
    "        \n",
    "        for num in extracted_numbers:\n",
    "            if num >= 1 and num <= len(step2_result_list[i]):\n",
    "                result += step2_result_list[i][num - 1] + '\\n'\n",
    "            else:\n",
    "                step3_result_list.append('None')\n",
    "                skip_list[i] = 1\n",
    "                continue\n",
    "        step3_result_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3_skip.json\"), \"w\") as f:\n",
    "    json.dump(skip_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Response Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4_template = \"\"\"Your task is to tackle mathematical problems step by step. You can refer to these demonstration to give your reasoning process.\n",
    "\n",
    "# Demonstration:\n",
    "{seed_demonstration}{checked_demonstration}# Instruction: Solve the following problem step by step.\n",
    "Question: {Question}\n",
    "Answer: Explain the step-by-step solution and enclose the ultimate answer in \\\\boxed{{}} here.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_template = \"\"\"Your task is to tackle mathematical problems step by step. You can refer to these demonstration to give your reasoning process.\n",
    "\n",
    "# Demonstration:\n",
    "{seed_demonstration}# Instruction: Solve the following problem step by step.\n",
    "Question: {Question}\n",
    "Answer: Explain the step-by-step solution and enclose the ultimate answer in \\\\boxed{{}} here.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if skip_list[i] == 1:\n",
    "        prompt = fewshot_template.format(\n",
    "            seed_demonstration=data[i][\"Demos_QA\"],\n",
    "            Question=data[i]['Question']\n",
    "        )   \n",
    "    else:\n",
    "        prompt = step4_template.format(\n",
    "            seed_demonstration=data[i][\"Demos_QA\"],\n",
    "            checked_demonstration=step3_result_list[i],\n",
    "            Question=data[i]['Question']\n",
    "        )\n",
    "        \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4_result_list = []\n",
    "\n",
    "for prompt in tqdm(prompt_list):\n",
    "    try_times = 0\n",
    "    while try_times < 5:\n",
    "        try: \n",
    "            result = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=2048,\n",
    "                temperature=0\n",
    "            )\n",
    "            # print(result)\n",
    "            step4_result_list.append(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            try_times += 1\n",
    "            if try_times == 5:\n",
    "                step4_result_list.append('None')\n",
    "            openai_key.process_error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step4.json\"), \"w\") as f:\n",
    "    json.dump(step4_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step4.json\"), 'r', encoding='utf8') as input_file:\n",
    "    result_list = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluate import evaluate_math\n",
    "print(f\"Accuracy: {evaluate_math(result_list, data)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
