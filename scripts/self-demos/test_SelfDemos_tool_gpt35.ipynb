{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "data_path = \"../../data/tool/clean_manual/tool_demo_hard_1k.json\"\n",
    "result_path = \"../../result/self_demos\"\n",
    "keys_file_path = \"../../utils/raw_keys.txt\"\n",
    "\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "suffix = \"tool_gpt35_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    raw_data = json.load(f)\n",
    "    \n",
    "\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_list = [0] * len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "for raw_item in tqdm(raw_data):\n",
    "    item = {}\n",
    "    item['Name'] = raw_item['Name']\n",
    "    item['Description'] = raw_item['Description']\n",
    "    \n",
    "    item['Specification'] = ''\n",
    "    item['Function_list'] = []\n",
    "    for key, value in raw_item['Function_Description'].items():\n",
    "        item['Specification'] += f\"{key}: {value}\\n\"\n",
    "        item['Function_list'].append(key)\n",
    "    \n",
    "    item['Demonstration'] = ''\n",
    "    for demo in raw_item['Demonstration']:\n",
    "        temp_demo_answer_list = []\n",
    "        for ans in demo['Answer']:\n",
    "            action = ans[\"Action\"]\n",
    "            action_input = json.loads(ans[\"Action_Input\"])  \n",
    "            formatted_input = ', '.join([f\"{key}='{value}'\" if isinstance(value, str) else f\"{key}={value}\" for key, value in action_input.items()])\n",
    "            formatted_call = f\"{action}({formatted_input})\"\n",
    "            temp_demo_answer_list.append(formatted_call)\n",
    "            \n",
    "        item['Demonstration'] += f\"Query: {demo['Instruction']}\\nFunction Calls: {temp_demo_answer_list}\\n\"\n",
    "        \n",
    "    item['Query'] = raw_item['Query']['Instruction']\n",
    "    \n",
    "    temp_answer_list = []\n",
    "    temp_answer_dict_list = []\n",
    "    for ans in raw_item['Query']['Answer']:\n",
    "        action = ans[\"Action\"]\n",
    "        action_input = json.loads(ans[\"Action_Input\"])  \n",
    "        \n",
    "        formatted_input = ', '.join([f\"{key}='{value}'\" if isinstance(value, str) else f\"{key}={value}\" for key, value in action_input.items()])\n",
    "        dict_input = ', '.join([f\"'{key}':'{value}'\" if isinstance(value, str) else f\"'{key}':{value}\" for key, value in action_input.items()])\n",
    "        \n",
    "        formatted_call = f\"{action}({formatted_input})\"\n",
    "        dict_call = f\"{action}(\" + \"{\" + f\"{dict_input}\" + \"})\"\n",
    "        \n",
    "        temp_answer_list.append(formatted_call)\n",
    "        temp_answer_dict_list.append(dict_call)\n",
    "    \n",
    "    item['Answer'] = temp_answer_list\n",
    "    item['AnswerDict'] = temp_answer_dict_list\n",
    "    \n",
    "    \n",
    "    data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openai import OpenAIKey, create_response_chat\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "openai_key = OpenAIKey(keys_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Query Understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_template = \"\"\"The {tool_name} API is used for {description}. In this task, you need to determine which function should be called according to a given query.\n",
    "\n",
    "# Tool Specification:\n",
    "{specification}\n",
    "# User Query:\n",
    "Query: {question}\n",
    "\n",
    "# Instruction:\n",
    "Function should be called: Give the function name here.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for item in data:\n",
    "    \n",
    "    prompt = step1_template.format(\n",
    "        tool_name=item[\"Name\"],\n",
    "        description=item['Description'],\n",
    "        specification=item['Specification'],\n",
    "        question=item['Query']\n",
    "    )\n",
    "    \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "step1_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(prompt_list))):\n",
    "    try_times = 0\n",
    "    while try_times < 5:\n",
    "        try: \n",
    "            response = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                ],\n",
    "                max_tokens=32,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            result = ' + '.join([func for func in data[i][\"Function_list\"] if func in response])\n",
    "            \n",
    "            if result != '':\n",
    "                # print(result)\n",
    "                step1_result_list.append(result)\n",
    "                break\n",
    "            else:\n",
    "                try_times += 1\n",
    "                print(result)\n",
    "                print(data[i][\"Function_list\"])\n",
    "                if try_times == 5:\n",
    "                    step1_result_list.append('None')\n",
    "                    skip_list[i] = 1\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            openai_key.process_error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step1.json\"), \"w\") as f:\n",
    "    json.dump(step1_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step1.json\"), 'r', encoding='utf8') as input_file:\n",
    "    step1_result_list = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step1_skip.json\"), \"w\") as f:\n",
    "    json.dump(skip_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Query-aware Demo Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_template = \"\"\"The {tool_name} API is used for {description}. In this task, you need to give an example of when to use the API, based on the specification.\n",
    "\n",
    "\n",
    "{specification}\n",
    "\n",
    "{seed_demonstration}\n",
    "\n",
    "Generate an example of how to use the `{function_picked}` function. For the example:\n",
    "- After \"Query: \", describe the problem.\n",
    "- After \"Function Calls: \", give the function calls in the format of [\"function_name(parameter=value)\"].\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for function_picked, item in zip(step1_result_list, data):\n",
    "    \n",
    "    prompt = step2_template.format(\n",
    "        tool_name=item[\"Name\"],\n",
    "        description=item['Description'],\n",
    "        specification=item['Specification'],\n",
    "        seed_demonstration=item['Demonstration'],\n",
    "        function_picked=function_picked\n",
    "    )\n",
    "    \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_step2_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(prompt_list))):\n",
    "    if skip_list[i] == 1:\n",
    "        raw_step2_result_list.append('None')\n",
    "        continue\n",
    "    \n",
    "    demo_candidate = []\n",
    "    \n",
    "    for _ in range(5):\n",
    "        try_times = 0\n",
    "        while try_times < 10:\n",
    "            try: \n",
    "                result = create_response_chat(\n",
    "                    MODEL,\n",
    "                    prompt_input=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                    ],\n",
    "                    max_tokens=256,\n",
    "                    temperature=0.8\n",
    "                )\n",
    "                # print(result)\n",
    "                demo_candidate.append(result)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                # print(repr(e))\n",
    "                try_times += 1\n",
    "                if try_times == 10:\n",
    "                    break\n",
    "                openai_key.process_error(e)\n",
    "    \n",
    "    raw_step2_result_list.append(demo_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step2.json\"), \"w\") as f:\n",
    "    json.dump(raw_step2_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step2.json\"), 'r', encoding='utf8') as input_file:\n",
    "    raw_step2_result_list = json.load(input_file)\n",
    "print(len(raw_step2_result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "step2_result_list = []\n",
    "\n",
    "def extract_key_lines(text):\n",
    "    text = text.replace('Query:\\n', 'Query: ').replace('Query: \\n', 'Query: ')\n",
    "    text = text.replace('Function Calls:\\n', 'Function Calls: ').replace('Function Calls: \\n', 'Function Calls: ')\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    lines = [line.strip() for line in lines]\n",
    "    \n",
    "    \n",
    "    query_lines = [line for line in lines if re.match(r'^(query)', line, re.IGNORECASE)]\n",
    "    \n",
    "    func_lines = [line for line in lines if re.match(r'^(function call)', line, re.IGNORECASE)]\n",
    "    \n",
    "    \n",
    "    query_lines = [line for line in query_lines if len(line) > 10]\n",
    "    func_lines = [line for line in func_lines if len(line) > 20]\n",
    "    \n",
    "    if len(query_lines) != 1 or len(func_lines) != 1:\n",
    "        return ''\n",
    "    \n",
    "    result = ''\n",
    "    for query_line, func_line in zip(query_lines, func_lines):\n",
    "        result += query_line + '\\n'\n",
    "        result += func_line + '\\n'\n",
    "    \n",
    "    return result\n",
    "\n",
    "for i in range(len(raw_step2_result_list)):\n",
    "    demo_candidate = []\n",
    "    for demo in raw_step2_result_list[i]:\n",
    "        \n",
    "        clean_result = extract_key_lines(demo)\n",
    "        if clean_result != '':\n",
    "            demo_candidate.append(clean_result)\n",
    "    \n",
    "    demo_candidate = list(set(demo_candidate))\n",
    "    \n",
    "    if len(demo_candidate) >= 2:\n",
    "        step2_result_list.append(demo_candidate)\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        step2_result_list.append(['None'])\n",
    "        skip_list[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step2_skip.json\"), \"w\") as f:\n",
    "    json.dump(skip_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Post-checking of Demos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_template = \"\"\"The {tool_name} API is used for {description}. Here are some examples for how to use the API. \n",
    "In this task, you need to check the examples for correctness and select one or two best examples to keep.\n",
    "\n",
    "# Tool Specification:\n",
    "{specification}\n",
    "# Check List:\n",
    "- Syntax errors: the function calls should conform to the format like `function_name(parameter=value)`.\n",
    "- Redundant parameters: the function calls must conform to the parameter list in the function specification. Never contain undeclared parameters or null parameters.\n",
    "- Value passing errors: the values of parameters should be in correct type and reasonable. Ignore null values.\n",
    "- Unsolvable errors: the query should be solvable with the given function.\n",
    "\n",
    "# Examples to be Checked:\n",
    "There are some use cases of the `{function_picked}` function you need to check.\n",
    "\n",
    "{generated_demonstration}\n",
    "\n",
    "# Instruction:\n",
    "Select one or two best examples to keep. If there are not enough correct examples, just keep one. Similar or identical examples can be kept only the best one.\n",
    "For your answer:\n",
    "- After \"Selection: \", give the serial numbers of your choice in the format of <x>, <y>.\n",
    "- After \"Explanation: \", give the reason why you keep this example.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for function_picked, generated_demonstration, item in zip(step1_result_list, step2_result_list, data):\n",
    "    \n",
    "    demo_string = ''\n",
    "    for i, demo in enumerate(generated_demonstration):\n",
    "        demo_string += f\"Example <{i+1}>:\\n{demo}\"\n",
    "    \n",
    "    prompt = step3_template.format(\n",
    "        tool_name=item[\"Name\"],\n",
    "        description=item['Description'],\n",
    "        specification=item['Specification'],\n",
    "        function_picked=function_picked,\n",
    "        function_picked_1=function_picked,\n",
    "        generated_demonstration=demo_string\n",
    "    )\n",
    "    \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_step3_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(prompt_list))):\n",
    "    if skip_list[i] == 1:\n",
    "        raw_step3_result_list.append('None')\n",
    "        continue\n",
    "    try_times = 0\n",
    "    while try_times < 5:\n",
    "        try: \n",
    "            result = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                ],\n",
    "                max_tokens=32,\n",
    "                temperature=0\n",
    "            )\n",
    "            # print(result)\n",
    "            raw_step3_result_list.append(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # print(repr(e))\n",
    "            try_times += 1\n",
    "            if try_times == 5:\n",
    "                raw_step3_result_list.append('None')\n",
    "                skip_list[i] = 1\n",
    "            openai_key.process_error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3.json\"), \"w\") as f:\n",
    "    json.dump(raw_step3_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3.json\"), 'r', encoding='utf8') as input_file:\n",
    "    raw_step3_result_list = json.load(input_file)\n",
    "print(len(raw_step3_result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "step3_result_list = []\n",
    "\n",
    "for i in range(len(raw_step3_result_list)):\n",
    "    if skip_list[i] == 1:\n",
    "        step3_result_list.append('None')\n",
    "    else: \n",
    "        matches = re.findall(r'<[1-5]>', raw_step3_result_list[i])\n",
    "    \n",
    "        \n",
    "        matches = list(set(matches))\n",
    "        \n",
    "        if not matches or len(matches) > 2:\n",
    "            step3_result_list.append('None')\n",
    "            skip_list[i] = 1\n",
    "            continue\n",
    "        \n",
    "        extracted_numbers = [int(match[1]) for match in matches]\n",
    "        result = ''\n",
    "        \n",
    "        for num in extracted_numbers:\n",
    "            if num >= 1 and num <= len(step2_result_list[i]):\n",
    "                result += step2_result_list[i][num - 1]\n",
    "            else:\n",
    "                step3_result_list.append('None')\n",
    "                skip_list[i] = 1\n",
    "                continue\n",
    "        step3_result_list.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3_skip.json\"), \"w\") as f:\n",
    "    json.dump(skip_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Response Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3_skip.json\"), \"r\") as f:\n",
    "    skip_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4_template = \"\"\"The {tool_name} API is used for {description}. In this task, you need to generate the function calls for a given query.\n",
    "\n",
    "# Tool Specification:\n",
    "{specification}\n",
    "# Demonstration:\n",
    "{seed_demonstration}{checked_demonstration}\n",
    "# Instruction: Solve the following user query.\n",
    "Query: {query}\n",
    "Function calls: Give your answer in the format of [\"function_name(parameter=value)\"] here.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_template = \"\"\"The {tool_name} API is used for {description}. In this task, you need to generate the function calls for a given query.\n",
    "\n",
    "# Tool Specification:\n",
    "{specification}\n",
    "# Demonstration:\n",
    "{seed_demonstration}\n",
    "# Instruction: Solve the following user query.\n",
    "Query: {query}\n",
    "Function calls: Give your answer in the format of [\"function_name(parameter=value)\"] here.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if skip_list[i] == 1:\n",
    "        prompt = fewshot_template.format(\n",
    "            tool_name=data[i][\"Name\"],\n",
    "            description=data[i]['Description'],\n",
    "            specification=data[i]['Specification'],\n",
    "            seed_demonstration=data[i]['Demonstration'],\n",
    "            query=data[i]['Query']\n",
    "        )\n",
    "    else:\n",
    "        prompt = step4_template.format(\n",
    "            tool_name=data[i][\"Name\"],\n",
    "            description=data[i]['Description'],\n",
    "            specification=data[i]['Specification'],\n",
    "            seed_demonstration=data[i]['Demonstration'],\n",
    "            checked_demonstration=step3_result_list[i],\n",
    "            query=data[i]['Query']\n",
    "        )\n",
    "        \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(len(prompt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(step3_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(prompt_list))):\n",
    "    try_times = 0\n",
    "    while try_times < 10:\n",
    "        try: \n",
    "            result = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                ],\n",
    "                max_tokens=512,\n",
    "                temperature=0\n",
    "            )\n",
    "            print(result)\n",
    "            step4_result_list.append(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            try_times += 1\n",
    "            if try_times == 10:\n",
    "                step4_result_list.append('None')\n",
    "            openai_key.process_error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step4.json\"), \"w\") as f:\n",
    "    json.dump(step4_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step4.json\"), 'r', encoding='utf8') as input_file:\n",
    "    result_list = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluate import evaluate_tool_exact_output, evaluate_tool_part_output\n",
    "\n",
    "print(f\"Exact Accuracy: {evaluate_tool_exact_output(result_list, data)}%\")\n",
    "print(f\"Part Accuracy: {evaluate_tool_part_output(result_list, data)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
