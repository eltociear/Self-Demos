{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"../../data/tool/test_demos.json\"\n",
    "result_path = \"../../result/self_demos\"\n",
    "keys_file_path = \"../../utils/raw_keys.txt\"\n",
    "\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "suffix = \"abla_post_sample+refine_tool_gpt35\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    raw_data = json.load(f)\n",
    "    \n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_list = [0] * len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "for raw_item in tqdm(raw_data):\n",
    "    item = {}\n",
    "    item['Name'] = raw_item['Name']\n",
    "    item['Description'] = raw_item['Description']\n",
    "    \n",
    "    item['Specification'] = ''\n",
    "    item['Function_list'] = []\n",
    "    for key, value in raw_item['Function_Description'].items():\n",
    "        item['Specification'] += f\"{key}: {value}\\n\"\n",
    "        item['Function_list'].append(key)\n",
    "    \n",
    "    item['Demonstration'] = ''\n",
    "    for demo in raw_item['Demonstration']:\n",
    "        temp_demo_answer_list = []\n",
    "        for ans in demo['Answer']:\n",
    "            action = ans[\"Action\"]\n",
    "            action_input = json.loads(ans[\"Action_Input\"])  \n",
    "            formatted_input = ', '.join([f\"{key}='{value}'\" if isinstance(value, str) else f\"{key}={value}\" for key, value in action_input.items()])\n",
    "            formatted_call = f\"{action}({formatted_input})\"\n",
    "            temp_demo_answer_list.append(formatted_call)\n",
    "            \n",
    "        item['Demonstration'] += f\"Query: {demo['Instruction']}\\nFunction Calls: {temp_demo_answer_list}\\n\"\n",
    "        \n",
    "    item['Query'] = raw_item['Query']['Instruction']\n",
    "    \n",
    "    temp_answer_list = []\n",
    "    temp_answer_dict_list = []\n",
    "    for ans in raw_item['Query']['Answer']:\n",
    "        action = ans[\"Action\"]\n",
    "        action_input = json.loads(ans[\"Action_Input\"])  \n",
    "        \n",
    "        formatted_input = ', '.join([f\"{key}='{value}'\" if isinstance(value, str) else f\"{key}={value}\" for key, value in action_input.items()])\n",
    "        dict_input = ', '.join([f\"'{key}':'{value}'\" if isinstance(value, str) else f\"'{key}':{value}\" for key, value in action_input.items()])\n",
    "        \n",
    "        formatted_call = f\"{action}({formatted_input})\"\n",
    "        dict_call = f\"{action}(\" + \"{\" + f\"{dict_input}\" + \"})\"\n",
    "        \n",
    "        temp_answer_list.append(formatted_call)\n",
    "        temp_answer_dict_list.append(dict_call)\n",
    "    \n",
    "    item['Answer'] = temp_answer_list\n",
    "    item['AnswerDict'] = temp_answer_dict_list\n",
    "    \n",
    "    \n",
    "    data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openai import OpenAIKey, create_response_chat\n",
    "\n",
    "openai_key = OpenAIKey(keys_file_path)\n",
    "MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"tool_gpt35_wo-thought+reject_1_step1.json\"), 'r', encoding='utf8') as input_file:\n",
    "    step1_result_list = json.load(input_file)\n",
    "\n",
    "step1_result_list.append(\"PublicHolidayNextPublicHolidays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../dataset/tool/generate_demos/demos_9_step2_result.json\", 'r', encoding='utf8') as input_file:\n",
    "    raw_step2_result_list = json.load(input_file)\n",
    "    \n",
    "len(raw_step2_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "raw_step2_result_list = [random.sample(demos, 5) for demos in raw_step2_result_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "step2_result_list = []\n",
    "\n",
    "def extract_key_lines(text):\n",
    "    text = text.replace('Query:\\n', 'Query: ').replace('Query: \\n', 'Query: ')\n",
    "    text = text.replace('Function Calls:\\n', 'Function Calls: ').replace('Function Calls: \\n', 'Function Calls: ')\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    lines = [line.strip() for line in lines]\n",
    "    \n",
    "    query_lines = [line for line in lines if re.match(r'^(query)', line, re.IGNORECASE)]\n",
    "    func_lines = [line for line in lines if re.match(r'^(function call)', line, re.IGNORECASE)]\n",
    "    \n",
    "    query_lines = [line for line in query_lines if len(line) > 10]\n",
    "    func_lines = [line for line in func_lines if len(line) > 20]\n",
    "    \n",
    "    if len(query_lines) != 1 or len(func_lines) != 1:\n",
    "        return ''\n",
    "\n",
    "    \n",
    "    result = ''\n",
    "    for query_line, func_line in zip(query_lines, func_lines):\n",
    "        result += query_line + '\\n'\n",
    "        result += func_line + '\\n'\n",
    "    \n",
    "    return result\n",
    "\n",
    "for i in range(len(raw_step2_result_list)):\n",
    "    demo_candidate = []\n",
    "    for demo in raw_step2_result_list[i]:\n",
    "        \n",
    "        clean_result = extract_key_lines(demo)\n",
    "        if clean_result != '':\n",
    "            demo_candidate.append(clean_result)\n",
    "    \n",
    "    demo_candidate = list(set(demo_candidate))\n",
    "    \n",
    "    if len(demo_candidate) >= 1:\n",
    "        step2_result_list.append(demo_candidate)\n",
    "    else:\n",
    "        step2_result_list.append(['None'])\n",
    "        skip_list[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step2_skip.json\"), \"w\") as f:\n",
    "    json.dump(skip_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Post-checking of Demos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_template = \"\"\"The {tool_name} API is used for {description}. Here are some examples for how to use the API. \n",
    "In this task, you need to check the examples for correctness and select one or two best examples to keep.\n",
    "\n",
    "# Tool Specification:\n",
    "{specification}\n",
    "# Check List:\n",
    "- Syntax errors: the function calls should conform to the format like `function_name(parameter=value)`.\n",
    "- Redundant parameters: the function calls must conform to the parameter list in the function specification. Never contain undeclared parameters or null parameters.\n",
    "- Value passing errors: the values of parameters should be in correct type and reasonable. Ignore null values.\n",
    "- Unsolvable errors: the query should be solvable with the given function.\n",
    "\n",
    "# Examples to be Checked:\n",
    "There are some use cases of the `{function_picked}` function you need to check.\n",
    "\n",
    "{generated_demonstration}\n",
    "# Instruction:\n",
    "Select one or two best examples to keep. If there are not enough correct examples, just keep one. Similar or identical examples can be kept only the best one.\n",
    "For your answer:\n",
    "- After \"Selection: \", give the serial numbers of your choice in the format of <x>, <y>.\n",
    "- After \"Explanation: \", give the reason why you keep this example.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for function_picked, generated_demonstration, item in zip(step1_result_list, step2_result_list, data):\n",
    "    demo_string = ''\n",
    "    for i, demo in enumerate(generated_demonstration):\n",
    "        demo_string += f\"Example <{i+1}>:\\n{demo}\"\n",
    "    \n",
    "    prompt = step3_template.format(\n",
    "        tool_name=item[\"Name\"],\n",
    "        description=item['Description'],\n",
    "        specification=item['Specification'],\n",
    "        function_picked=function_picked,\n",
    "        function_picked_1=function_picked,\n",
    "        generated_demonstration=demo_string\n",
    "    )\n",
    "    \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_step3_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(prompt_list))):\n",
    "    if skip_list[i] == 1:\n",
    "        raw_step3_result_list.append('None')\n",
    "        continue\n",
    "    try_times = 0\n",
    "    while try_times < 5:\n",
    "        try: \n",
    "            result = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                ],\n",
    "                max_tokens=32,\n",
    "                temperature=0\n",
    "            )\n",
    "            # print(result)\n",
    "            raw_step3_result_list.append(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # print(repr(e))\n",
    "            try_times += 1\n",
    "            if try_times == 5:\n",
    "                raw_step3_result_list.append('None')\n",
    "                skip_list[i] = 1\n",
    "            openai_key.process_error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3.json\"), \"w\") as f:\n",
    "    json.dump(raw_step3_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3.json\"), 'r', encoding='utf8') as input_file:\n",
    "    raw_step3_result_list = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "step3_result_list = []\n",
    "\n",
    "for i in range(len(raw_step3_result_list)):\n",
    "    if skip_list[i] == 1:\n",
    "        step3_result_list.append('None')\n",
    "    else: \n",
    "        matches = re.findall(r'<[1-5]>', raw_step3_result_list[i])\n",
    "        matches = list(set(matches))\n",
    "        \n",
    "        if not matches or len(matches) > 2:\n",
    "            step3_result_list.append('None')\n",
    "            skip_list[i] = 1\n",
    "            continue\n",
    "        \n",
    "        extracted_numbers = [int(match[1]) for match in matches]\n",
    "        result = ''\n",
    "        \n",
    "        for num in extracted_numbers:\n",
    "            if num >= 1 and num <= len(step2_result_list[i]):\n",
    "                result += step2_result_list[i][num - 1]\n",
    "            else:\n",
    "                step3_result_list.append('None')\n",
    "                skip_list[i] = 1\n",
    "                continue\n",
    "        step3_result_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3_skip.json\"), \"w\") as f:\n",
    "    json.dump(skip_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.5: Refine of Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_1_template = \"\"\"The {tool_name} API is used for {description}. Here are some examples for how to use the API. \n",
    "In this task, you need to check and refine the use cases of the API.\n",
    "\n",
    "# Tool Specification:\n",
    "{specification}\n",
    "# Check List:\n",
    "- Syntax errors: the function calls should conform to the format like `function_name(parameter=value)`.\n",
    "- Redundant parameters: the function calls must conform to the parameter list in the function specification. Never contain undeclared parameters or null parameters.\n",
    "- Value passing errors: the values of parameters should be in correct type and reasonable. Ignore null values.\n",
    "- Unsolvable errors: the query should be solvable with the given function.\n",
    "\n",
    "# Examples to be Checked:\n",
    "There are some use cases of the `{function_picked}` function you need to check.\n",
    "\n",
    "{generated_demonstration}\n",
    "# Instruction:\n",
    "Check and refine the eaxmples. If it is already correct, just copy it to the output, without any modification. If there are errors, correct them and then output. \n",
    "For your output of checked examples:\n",
    "- After \"Query: \", copy the query of the example to here.\n",
    "- After \"Function Calls: \", give the checked function calls of the example.\n",
    "You don't need to have any other additional output.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for function_picked, generated_demonstration, item in zip(step1_result_list, step3_result_list, data):\n",
    "    prompt = step3_1_template.format(\n",
    "        tool_name=item[\"Name\"],\n",
    "        description=item['Description'],\n",
    "        specification=item['Specification'],\n",
    "        function_picked=function_picked,\n",
    "        generated_demonstration=generated_demonstration\n",
    "    )\n",
    "    \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_step3_1_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(prompt_list))):\n",
    "    if skip_list[i] == 1:\n",
    "        raw_step3_1_result_list.append('None')\n",
    "        continue\n",
    "    try_times = 0\n",
    "    while try_times < 5:\n",
    "        try: \n",
    "            result = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                ],\n",
    "                max_tokens=512,\n",
    "                temperature=0\n",
    "            )\n",
    "            # print(result)\n",
    "            raw_step3_1_result_list.append(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # print(repr(e))\n",
    "            try_times += 1\n",
    "            if try_times == 5:\n",
    "                raw_step3_1_result_list.append('None')\n",
    "                skip_list[i] = 1\n",
    "            openai_key.process_error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3_1.json\"), \"w\") as f:\n",
    "    json.dump(raw_step3_1_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3_1.json\"), 'r', encoding='utf8') as input_file:\n",
    "    raw_step3_1_result_list = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "step3_1_result_list = []\n",
    "\n",
    "def extract_key_lines(text):\n",
    "    \n",
    "    text = text.replace('Query:\\n', 'Query: ').replace('Query: \\n', 'Query: ')\n",
    "    text = text.replace('Function Calls:\\n', 'Function Calls: ').replace('Function Calls: \\n', 'Function Calls: ')\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    lines = [line.strip() for line in lines]    \n",
    "    \n",
    "    query_lines = [line for line in lines if re.match(r'^(query)', line, re.IGNORECASE)]\n",
    "    func_lines = [line for line in lines if re.match(r'^(function call)', line, re.IGNORECASE)]\n",
    "    \n",
    "    query_lines = [line for line in query_lines if len(line) > 10]\n",
    "    func_lines = [line for line in func_lines if len(line) > 20]\n",
    "\n",
    "    if len(query_lines) != 2 or len(func_lines) != 2:\n",
    "        return ''\n",
    "        \n",
    "    result = ''\n",
    "    for query_line, func_line in zip(query_lines, func_lines):\n",
    "        result += query_line + '\\n'\n",
    "        result += func_line + '\\n'\n",
    "    \n",
    "    return result\n",
    "\n",
    "for i in range(len(raw_step3_1_result_list)):\n",
    "    \n",
    "    clean_result = extract_key_lines(raw_step3_1_result_list[i])\n",
    "    \n",
    "    if clean_result != '':\n",
    "        step3_1_result_list.append(clean_result)\n",
    "    else:\n",
    "        step3_1_result_list.append('None')\n",
    "        skip_list[i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(skip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3_1_skip.json\"), \"w\") as f:\n",
    "    json.dump(skip_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Response Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step3_1_skip.json\"), \"r\") as f:\n",
    "    skip_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4_template = \"\"\"The {tool_name} API is used for {description}. In this task, you need to generate the function calls for a given query.\n",
    "\n",
    "# Tool Specification:\n",
    "{specification}\n",
    "# Demonstration:\n",
    "{seed_demonstration}{checked_demonstration}\n",
    "# Instruction: Solve the following user query.\n",
    "Query: {query}\n",
    "Function calls: Give your answer in the format of [\"function_name(parameter=value)\"] here.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_template = \"\"\"The {tool_name} API is used for {description}. In this task, you need to generate the function calls for a given query.\n",
    "\n",
    "# Tool Specification:\n",
    "{specification}\n",
    "# Demonstration:\n",
    "{seed_demonstration}\n",
    "# Instruction: Solve the following user query.\n",
    "Query: {query}\n",
    "Function calls: Give your answer in the format of [\"function_name(parameter=value)\"] here.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if skip_list[i] == 1:\n",
    "        prompt = fewshot_template.format(\n",
    "            tool_name=data[i][\"Name\"],\n",
    "            description=data[i]['Description'],\n",
    "            specification=data[i]['Specification'],\n",
    "            seed_demonstration=data[i]['Demonstration'],\n",
    "            query=data[i]['Query']\n",
    "        )\n",
    "    else:\n",
    "        prompt = step4_template.format(\n",
    "            tool_name=data[i][\"Name\"],\n",
    "            description=data[i]['Description'],\n",
    "            specification=data[i]['Specification'],\n",
    "            seed_demonstration=data[i]['Demonstration'],\n",
    "            checked_demonstration=step3_1_result_list[i],\n",
    "            query=data[i]['Query']\n",
    "        )\n",
    "        \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4_result_list = []\n",
    "\n",
    "for i in tqdm(range(len(prompt_list))):\n",
    "    try_times = 0\n",
    "    while try_times < 10:\n",
    "        try: \n",
    "            result = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                ],\n",
    "                max_tokens=512,\n",
    "                temperature=0\n",
    "            )\n",
    "            # print(result)\n",
    "            step4_result_list.append(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            try_times += 1\n",
    "            if try_times == 10:\n",
    "                step4_result_list.append('None')\n",
    "            openai_key.process_error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step4.json\"), \"w\") as f:\n",
    "    json.dump(step4_result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}_step4.json\"), 'r', encoding='utf8') as input_file:\n",
    "    result_list = json.load(input_file)\n",
    "print(len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluate import evaluate_tool_exact_output, evaluate_tool_part_output\n",
    "\n",
    "print(f\"Exact Accuracy: {evaluate_tool_exact_output(result_list, data)}%\")\n",
    "print(f\"Part Accuracy: {evaluate_tool_part_output(result_list, data)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
