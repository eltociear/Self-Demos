{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"../../data/gsm8k/test_demos.json\"\n",
    "result_path = \"../../result/analog\"\n",
    "keys_file_path = \"../../utils/raw_keys.txt\"\n",
    "\n",
    "\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "    \n",
    "suffix = \"gsm8k_gpt35_fewshot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    raw_data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "for raw_item in tqdm(raw_data):\n",
    "    item = {}\n",
    "    item['Question'] = raw_item['problem']\n",
    "    item['Answer'] = raw_item['answer']\n",
    "    \n",
    "    item['Demos_Q'] = ''\n",
    "    item['Demos_QA'] = ''\n",
    "    \n",
    "    for demo in raw_item['demos']:\n",
    "        item['Demos_Q'] += f\"Question: {demo['problem']}\\n\\n\"\n",
    "        item['Demos_QA'] += f\"Question: {demo['problem']}\\nAnswer: {demo['solution']}\\n\\n\"\n",
    "        \n",
    "    data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openai import OpenAIKey, create_response_chat\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "openai_key = OpenAIKey(keys_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analog Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_template = \"\"\"Your task is to tackle mathematical problems. When presented with a math problem, recall relevant problems as examples. Afterward, proceed to solve the initial problem.\n",
    "\n",
    "# Demonstration:\n",
    "You can refer to these demonstration to give your reasoning process.\n",
    "{seed_demonstration}# Initial Problem:\n",
    "{Question}\n",
    "\n",
    "# Instruction:\n",
    "## Relevant Problems:\n",
    "Recall three examples of math problems that are relevant to the initial problem. Your problems should be distinct from each other and from the initial problem (e.g., involving different numbers and names). For each problem:\n",
    "- After \"Question: \", describe the problem.\n",
    "- After \"Answer: \", explain the solution and enclose the ultimate answer in \\\\boxed{{}}.\n",
    "\n",
    "## Solve the Initial Problem:\n",
    "Question: Copy and paste the initial problem here. \n",
    "Answer: Explain the solution and enclose the ultimate answer in \\\\boxed{{}} here.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "\n",
    "for item in data:\n",
    "    prompt = analog_template.format(\n",
    "        seed_demonstration=item[\"Demos_QA\"],\n",
    "        Question=item['Question']\n",
    "    )   \n",
    "    prompt_list.append(prompt)\n",
    "    \n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    try_times = 0\n",
    "    while try_times < 20:\n",
    "        try: \n",
    "            result = create_response_chat(\n",
    "                MODEL,\n",
    "                prompt_input=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_list[i]}\n",
    "                ],\n",
    "                max_tokens=1024,\n",
    "                temperature=0\n",
    "            )\n",
    "            # print(result)\n",
    "            result_list.append(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # print(repr(e))\n",
    "            try_times += 1\n",
    "            if try_times == 20:\n",
    "                result_list.append('None')\n",
    "            openai_key.process_error(e)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}.json\"), \"w\") as f:\n",
    "    json.dump(result_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"{suffix}.json\"), 'r', encoding='utf8') as input_file:\n",
    "    result_list = json.load(input_file)\n",
    "print(len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluate import evaluate_gsm8k\n",
    "\n",
    "print(f\"Accuracy: {evaluate_gsm8k(result_list, data)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
